#!/usr/bin/env python3
"""
Diesel-Goose Context Monitor
Automatically saves state and triggers compaction at 123K tokens

Monitors context window usage and preserves operations
"""

import json
import os
import subprocess
from pathlib import Path
from datetime import datetime

# Configuration
CONTEXT_THRESHOLD = 123000  # 123K tokens
WARNING_THRESHOLD = 100000  # 100K - early warning
CHECK_INTERVAL = 300  # Check every 5 minutes (if running as daemon)

class ContextMonitor:
    """Monitor and manage context window usage"""
    
    def __init__(self):
        self.workspace = Path.home() / "Documents" / "HonkNode" / "Duck-Pond"
        self.log_file = self.workspace / ".context_monitor.log"
        
    def check_context_size(self):
        """Get current context size from OpenClaw"""
        try:
            # Check if we can get context info from OpenClaw
            result = subprocess.run(
                ["openclaw", "status"],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            # Parse output for context info
            # This is a placeholder - actual implementation depends on OpenClaw output format
            output = result.stdout
            
            # Look for context size in output
            # Example: "Context: 45000/256000 tokens"
            if "context" in output.lower():
                # Extract number - this is simplified
                return self._parse_context(output)
            
            return None
            
        except Exception as e:
            self.log(f"Error checking context: {e}")
            return None
    
    def _parse_context(self, output):
        """Parse context size from OpenClaw status"""
        # This would need to be adjusted based on actual OpenClaw output format
        try:
            # Look for patterns like "45K/256K" or "45000/256000"
            import re
            match = re.search(r'(\d+(?:,\d+)?)(?:K)?\s*/\s*(\d+(?:,\d+)?)(?:K)?', output)
            if match:
                current = int(match.group(1).replace(',', ''))
                if 'K' in output[:match.end()]:
                    current *= 1000
                return current
        except:
            pass
        return None
    
    def save_critical_state(self):
        """Save all important information before compaction"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.workspace / "System" / "context_backups"
        backup_dir.mkdir(exist_ok=True)
        
        backup_file = backup_dir / f"CRITICAL_STATE_{timestamp}.md"
        
        content = f"""# Critical State Backup - {datetime.now().isoformat()}

## Session Information
- **Date:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **Trigger:** Context approaching 123K limit
- **Status:** Auto-save initiated

## Active Operations

### Current Tasks
- [ ] Brave Browser extension installation
- [ ] Mercury account funding ($5-10K)
- [ ] Web3 product development planning
- [ ] OpenClaw context compaction

### Pending Actions
1. Fund Mercury account
2. Install OpenClaw extension
3. Create virtual cards
4. Build first Web3 product MVP
5. File FinCEN BOI report

## Active Integrations
- âœ… XRPL/Xaman: Connected
- âœ… Flare Network: Operational
- âœ… Mercury Bank: API active (balance: $0.06)
- âœ… Brave Search: Working
- ðŸŸ¡ Brave Browser: Extension pending

## Current Priorities
1. Complete Mercury setup
2. Install browser extension
3. Start revenue-generating automations

## Resume Instructions
1. Check context size: `/status` or `session_status`
2. If compacted, reference this backup
3. Continue from pending actions
4. Execute next priority

---
**Auto-generated by Diesel-Goose Context Monitor**
**Preserve this file for session continuity**
"""
        
        with open(backup_file, 'w') as f:
            f.write(content)
        
        self.log(f"Critical state saved: {backup_file}")
        return backup_file
    
    def trigger_compaction(self):
        """Trigger context compaction via OpenClaw"""
        try:
            # Save state first
            backup_file = self.save_critical_state()
            
            # Log the compaction trigger
            self.log(f"Context threshold reached ({CONTEXT_THRESHOLD}). Triggering compaction.")
            
            # Create resume instructions
            resume_file = self.workspace / "RESUME_AFTER_COMPACTION.md"
            with open(resume_file, 'w') as f:
                f.write(f"""# Resume Operations After Compaction

## Compaction Triggered: {datetime.now().isoformat()}

### Immediate Actions on Return:
1. **Check Context Status**
   - Run: `session_status` or `/status`
   - Verify context is below 50K tokens

2. **Load Critical State**
   - Reference: {backup_file.name}
   - Review pending actions

3. **Resume Priority Tasks**
   Priority 1: Fund Mercury account
   Priority 2: Install OpenClaw extension  
   Priority 3: Start revenue automations

4. **Verify Integrations**
   - Mercury API: `dp mercury ping`
   - XRPL: `dp xaman ping`
   - Flare: `dp flare ping`
   - Brave: `dp brave "test"`

### Quick Commands:
```bash
# Check all systems
dp mercury ping && dp xaman ping && dp flare ping

# View backup
open ~/Honk-Node/Duck-Pond/System/context_backups/{backup_file.name}

# Continue work
cd ~/Honk-Node/Duck-Pond
```

### Contact:
If issues arise, contact Nathan at nathan@greenhead.io

---
**Auto-generated at context threshold**
**Ready to resume operations**
""")
            
            self.log("Compaction prepared. Ready for /compact command.")
            
            # Return instructions for user
            return {
                "status": "ready_for_compaction",
                "backup_file": str(backup_file),
                "resume_file": str(resume_file),
                "message": "Critical state saved. Run /compact now."
            }
            
        except Exception as e:
            self.log(f"Error during compaction prep: {e}")
            return {"status": "error", "error": str(e)}
    
    def log(self, message):
        """Write to monitor log"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(self.log_file, 'a') as f:
            f.write(f"[{timestamp}] {message}\n")
    
    def check_and_act(self):
        """Main check routine"""
        context_size = self.check_context_size()
        
        if context_size is None:
            # If we can't check, assume we need backup
            self.log("Cannot determine context size. Manual check recommended.")
            return {"status": "unknown", "action": "manual_check"}
        
        self.log(f"Context size: {context_size} tokens")
        
        if context_size >= CONTEXT_THRESHOLD:
            # Trigger compaction preparation
            return self.trigger_compaction()
        elif context_size >= WARNING_THRESHOLD:
            # Warning level
            self.log(f"WARNING: Context at {context_size}K (threshold: {CONTEXT_THRESHOLD}K)")
            return {
                "status": "warning",
                "context_size": context_size,
                "threshold": CONTEXT_THRESHOLD,
                "message": f"Context at {context_size}K. Approaching {CONTEXT_THRESHOLD}K limit."
            }
        else:
            # Normal operation
            return {
                "status": "normal",
                "context_size": context_size,
                "message": f"Context healthy: {context_size}K / {CONTEXT_THRESHOLD}K"
            }

def main():
    """CLI interface"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Diesel-Goose Context Monitor")
    parser.add_argument("--check", action="store_true", help="Check context now")
    parser.add_argument("--save", action="store_true", help="Save critical state immediately")
    parser.add_argument("--threshold", type=int, default=123000, help="Token threshold (default: 123000)")
    
    args = parser.parse_args()
    
    monitor = ContextMonitor()
    
    if args.save:
        print("ðŸ¦† Saving critical state...")
        backup = monitor.save_critical_state()
        print(f"âœ… Saved: {backup}")
        print(f"âœ… Resume file created: ~/Honk-Node/Duck-Pond/RESUME_AFTER_COMPACTION.md")
        print("\nReady for: /compact")
    
    elif args.check:
        result = monitor.check_and_act()
        print(json.dumps(result, indent=2))
    
    else:
        # Default: check and report
        result = monitor.check_and_act()
        print(f"Status: {result['status']}")
        print(f"Message: {result['message']}")
        
        if result['status'] == 'ready_for_compaction':
            print(f"\nâœ… Backup: {result['backup_file']}")
            print(f"âœ… Resume: {result['resume_file']}")
            print("\nðŸ¦† Run /compact now to free context space!")

if __name__ == "__main__":
    main()
